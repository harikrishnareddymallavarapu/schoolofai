# Back Propogation in Neural Networks

## Screenshot of the Network training in excel

### Model and Gradient Calculation
![image](https://user-images.githubusercontent.com/24980224/118105606-378b3d00-b3fa-11eb-8ab0-ff6fd5f76db3.png)

### Training of network in Excel
![image](https://user-images.githubusercontent.com/24980224/118106281-0f500e00-b3fb-11eb-9daf-135fb278a0b1.png)

## Drop in error at different Learning Rates
<img src="https://user-images.githubusercontent.com/24980224/118105293-d4010f80-b3f9-11eb-9323-c1a70f2d4664.png" width="100" height="100"/>

![image](https://user-images.githubusercontent.com/24980224/118105293-d4010f80-b3f9-11eb-9323-c1a70f2d4664.png)

## Below is the explanation of the model

Here we will explain the back propagation of the below neural network

![image](https://user-images.githubusercontent.com/24980224/118081121-642e5d00-b3d8-11eb-8ad2-f422454b94f8.png)

Here i1 and i2 are inputs to layer 1 and w1, w2, w3, w4 are corresponding weights for the layers and below is the calculations done in layer 1

![image](https://user-images.githubusercontent.com/24980224/118082954-b6bd4880-b3db-11eb-8fad-86c72adc06dc.png)

Here a_h1 and a_h2 are inputs to layer 2 and w5, w6, w7, w8 are corresponding weights for the layers and below is the calculations done in layer 2 or output

![image](https://user-images.githubusercontent.com/24980224/118083113-f6843000-b3db-11eb-9e68-fb8337debe9b.png)

Here is the final error generated by the network 

![image](https://user-images.githubusercontent.com/24980224/118083137-03a11f00-b3dc-11eb-9f08-a99d34f03f8c.png)



