# Back Propogation in Neural Networks

In this file we will explain the back propagation of the below neural network

![image](https://user-images.githubusercontent.com/24980224/118081121-642e5d00-b3d8-11eb-8ad2-f422454b94f8.png)

Here i1 and i2 are inputs to layer 1 and w1, w2, w3, w4 are corresponding weights for the layers and below is the calculations done in layer 1

![image](https://user-images.githubusercontent.com/24980224/118082954-b6bd4880-b3db-11eb-8fad-86c72adc06dc.png)

Here a_h1 and a_h2 are inputs to layer 2 and w5, w6, w7, w8 are corresponding weights for the layers and below is the calculations done in layer 2 or output

![image](https://user-images.githubusercontent.com/24980224/118083113-f6843000-b3db-11eb-9e68-fb8337debe9b.png)

Here is the final error genrated by the network 

![image](https://user-images.githubusercontent.com/24980224/118083137-03a11f00-b3dc-11eb-9f08-a99d34f03f8c.png)



